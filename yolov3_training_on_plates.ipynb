{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "yolov3 - training on plates.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "F1t9oTEo3jaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.13.1\n",
        "!pip install -U keras opencv-python\n",
        "!pip3 install imageai --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB6JoAAl91wb",
        "colab_type": "code",
        "outputId": "a448b91e-3c5f-45ef-cb36-2760f9425c7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3yvk_Nus3jas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tiny download and .h5 convert\n",
        "# !wget https://github.com/pjreddie/darknet/blob/master/cfg/yolov3-tiny.cfg\n",
        "# !wget https://pjreddie.com/media/files/yolov3-tiny.weights\n",
        "# !git clone https://github.com/qqwweee/keras-yolo3.git\n",
        "# !python ./keras-yolo3/convert.py ./keras-yolo3/yolov3-tiny.cfg ./yolov3-tiny.weights ./yolo-tiny.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgFkNldFCOyq",
        "colab_type": "code",
        "outputId": "12fd0cd2-c716-44aa-921f-b2a98b43c131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_name = 'detection_model-ex-03--loss-3.57.h5'\n",
        "!cp /content/drive/My\\ Drive/Vision/$model_name ./\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "detection_model-ex-03--loss-3.57.h5  drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0o3Wz3HR3jbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xvf /content/drive/My\\ Drive/Vision/plates.tar\n",
        "!mkdir plates && mv train ./plates && mv validation ./plates\n",
        "!rm ./plates/validation/annotations/200.xml\n",
        "!rm -r sample_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YV2QO5mO3jbW",
        "colab_type": "code",
        "outputId": "a18f769a-1408-4d86-daaa-b5b47f99a9a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import subprocess\n",
        "\n",
        "from imageai.Detection.Custom import DetectionModelTrainer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vvaOGSab3jbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainer = DetectionModelTrainer()\n",
        "trainer.setModelTypeAsYOLOv3()\n",
        "trainer.setDataDirectory(data_directory=\"plates\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBzoxuzlC6mP",
        "colab_type": "code",
        "outputId": "ed7844e4-57ee-48bd-f9ca-8d3db518960c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trainer.setTrainConfig(object_names_array=[\"license plate\"], batch_size=4, num_experiments=1, train_from_pretrained_model=model_name)\n",
        "trainer.trainModel()\n",
        "\n",
        "for i in range(60):\n",
        "  list_of_files = glob.glob('plates/models/*.h5') \n",
        "  print(list_of_files) \n",
        "  latest_file = max(list_of_files, key=os.path.getctime)\n",
        "  subprocess.call(['rm ./*.h5'],shell=True)\n",
        "  subprocess.call(['cp ' + latest_file + ' ./'],shell=True)\n",
        "  subprocess.call(['mv ' + latest_file + ' /content/drive/My\\ Drive/Vision/'],shell=True)\n",
        "  subprocess.call(['rm plates/models/*.h5'],shell=True)\n",
        "  model = glob.glob('./*.h5')[0]\n",
        "  print('model to train ',model)\n",
        "  trainer.setTrainConfig(object_names_array=[\"license plate\"], batch_size=4, num_experiments=5, train_from_pretrained_model=model)\n",
        "  trainer.trainModel()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.78\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  plates/json/detection_config.json\n",
            "Training on: \t['license plate']\n",
            "Training with Batch Size:  4\n",
            "Number of Experiments:  1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/imageai/Detection/Custom/yolo.py:24: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Training with transfer learning from pretrained Model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/1\n",
            " - 603s - loss: 5.6119 - yolo_layer_1_loss: 0.4834 - yolo_layer_2_loss: 2.5938 - yolo_layer_3_loss: 2.5347 - val_loss: 14.7366 - val_yolo_layer_1_loss: 1.9647 - val_yolo_layer_2_loss: 5.9862 - val_yolo_layer_3_loss: 6.7857\n",
            "['plates/models/detection_model-ex-01--loss-5.61.h5']\n",
            "model to train  ./detection_model-ex-01--loss-5.61.h5\n",
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.78\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  plates/json/detection_config.json\n",
            "Training on: \t['license plate']\n",
            "Training with Batch Size:  4\n",
            "Number of Experiments:  5\n",
            "Training with transfer learning from pretrained Model\n",
            "Epoch 1/5\n",
            " - 605s - loss: 4.5930 - yolo_layer_4_loss: 0.5561 - yolo_layer_5_loss: 1.9455 - yolo_layer_6_loss: 2.0914 - val_loss: 14.1158 - val_yolo_layer_4_loss: 1.6584 - val_yolo_layer_5_loss: 5.8313 - val_yolo_layer_6_loss: 6.6261\n",
            "Epoch 2/5\n",
            " - 517s - loss: 3.6386 - yolo_layer_4_loss: 0.5279 - yolo_layer_5_loss: 1.2910 - yolo_layer_6_loss: 1.8197 - val_loss: 14.9107 - val_yolo_layer_4_loss: 2.0841 - val_yolo_layer_5_loss: 6.0752 - val_yolo_layer_6_loss: 6.7514\n",
            "Epoch 3/5\n",
            " - 536s - loss: 3.6608 - yolo_layer_4_loss: 0.5300 - yolo_layer_5_loss: 1.3655 - yolo_layer_6_loss: 1.7652 - val_loss: 15.0053 - val_yolo_layer_4_loss: 2.8251 - val_yolo_layer_5_loss: 5.9843 - val_yolo_layer_6_loss: 6.1959\n",
            "Epoch 4/5\n",
            " - 525s - loss: 3.8006 - yolo_layer_4_loss: 0.5363 - yolo_layer_5_loss: 1.3372 - yolo_layer_6_loss: 1.9272 - val_loss: 14.4461 - val_yolo_layer_4_loss: 2.3254 - val_yolo_layer_5_loss: 5.3570 - val_yolo_layer_6_loss: 6.7637\n",
            "Epoch 5/5\n",
            " - 527s - loss: 3.2046 - yolo_layer_4_loss: 0.4412 - yolo_layer_5_loss: 1.1516 - yolo_layer_6_loss: 1.6119 - val_loss: 15.3301 - val_yolo_layer_4_loss: 2.7529 - val_yolo_layer_5_loss: 6.3215 - val_yolo_layer_6_loss: 6.2558\n",
            "['plates/models/detection_model-ex-01--loss-4.59.h5', 'plates/models/detection_model-ex-02--loss-3.64.h5', 'plates/models/detection_model-ex-05--loss-3.20.h5']\n",
            "model to train  ./detection_model-ex-05--loss-3.20.h5\n",
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.78\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  plates/json/detection_config.json\n",
            "Training on: \t['license plate']\n",
            "Training with Batch Size:  4\n",
            "Number of Experiments:  5\n",
            "Training with transfer learning from pretrained Model\n",
            "Epoch 1/5\n",
            " - 607s - loss: 4.6342 - yolo_layer_7_loss: 0.5827 - yolo_layer_8_loss: 1.8157 - yolo_layer_9_loss: 2.2358 - val_loss: 14.3962 - val_yolo_layer_7_loss: 2.5015 - val_yolo_layer_8_loss: 6.8765 - val_yolo_layer_9_loss: 5.0182\n",
            "Epoch 2/5\n",
            " - 526s - loss: 3.2386 - yolo_layer_7_loss: 0.5109 - yolo_layer_8_loss: 1.2539 - yolo_layer_9_loss: 1.4738 - val_loss: 14.4561 - val_yolo_layer_7_loss: 2.3693 - val_yolo_layer_8_loss: 7.2456 - val_yolo_layer_9_loss: 4.8412\n",
            "Epoch 3/5\n",
            " - 536s - loss: 3.3100 - yolo_layer_7_loss: 0.4848 - yolo_layer_8_loss: 1.3786 - yolo_layer_9_loss: 1.4466 - val_loss: 15.1777 - val_yolo_layer_7_loss: 2.8884 - val_yolo_layer_8_loss: 7.0206 - val_yolo_layer_9_loss: 5.2687\n",
            "Epoch 4/5\n",
            " - 537s - loss: 3.5261 - yolo_layer_7_loss: 0.6079 - yolo_layer_8_loss: 1.3356 - yolo_layer_9_loss: 1.5827 - val_loss: 14.6080 - val_yolo_layer_7_loss: 2.3889 - val_yolo_layer_8_loss: 6.7933 - val_yolo_layer_9_loss: 5.4258\n",
            "Epoch 5/5\n",
            " - 530s - loss: 2.9875 - yolo_layer_7_loss: 0.4468 - yolo_layer_8_loss: 1.2142 - yolo_layer_9_loss: 1.3265 - val_loss: 14.3010 - val_yolo_layer_7_loss: 1.8714 - val_yolo_layer_8_loss: 6.9469 - val_yolo_layer_9_loss: 5.4827\n",
            "['plates/models/detection_model-ex-02--loss-3.24.h5', 'plates/models/detection_model-ex-05--loss-2.99.h5', 'plates/models/detection_model-ex-01--loss-4.63.h5']\n",
            "model to train  ./detection_model-ex-05--loss-2.99.h5\n",
            "Generating anchor boxes for training images and annotation...\n",
            "Average IOU for 9 anchors: 0.78\n",
            "Anchor Boxes generated.\n",
            "Detection configuration saved in  plates/json/detection_config.json\n",
            "Training on: \t['license plate']\n",
            "Training with Batch Size:  4\n",
            "Number of Experiments:  5\n",
            "Training with transfer learning from pretrained Model\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2PohWG2HpXO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}